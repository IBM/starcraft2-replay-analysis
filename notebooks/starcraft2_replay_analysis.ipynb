{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n",
    "# not use this file except in compliance with the License. You may obtain\n",
    "# a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n",
    "# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n",
    "# License for the specific language governing permissions and limitations\n",
    "# under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StarCraft II Replay Analysis\n",
    "\n",
    "This developer journey will guide you through StarCraft II replay analysis.\n",
    "\n",
    "> Note: Instructions assume this notebook is running in IBM Data Science Experience (DSX).\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "This journey covers the following learning goals:\n",
    "\n",
    "1. Getting started with DSX notebooks\n",
    "3. Using DSX Object Storage to access a replay file\n",
    "3. Using sc2reader to load a replay into a Python object\n",
    "4. Examining some of the basic replay information in the result\n",
    "5. Parsing the contest details into a usable object\n",
    "6. Visualizing the contest with graphics\n",
    "7. Storing the processed replay in Cloudant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup prerequisites and credentials\n",
    "### Install the _sc2reader_ and _cloudant_ Python packages from PyPI\n",
    "\n",
    "* **_sc2reader_** is an open source library for processing StarCraft 2 replay files.\n",
    "* **_cloudant_** is the Python client for using the Cloudant NoSQL DB.\n",
    "\n",
    "We install the prerequisites using the `!pip install` syntax here. In some cases, running pip install from a notebook may require a one-time kernel restart. Check the output for messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install sc2reader cloudant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the replay file with DSX \"Insert to code\"\n",
    "\n",
    "#### Add the replay to the notebook\n",
    "Use \"Find and Add Data\" (look for the 10/01 icon)\n",
    "and its \"Files\" tab. From there you can click\n",
    "\"browse\" and add a .SC2Replay file from your computer.\n",
    "\n",
    "#### Create an empty cell\n",
    "Use the \"+\" button above to create an empty cell to hold\n",
    "the inserted code and credentials.\n",
    "\n",
    "#### Insert to code\n",
    "After you add the file, use its \"Insert to code\" drop-down menu.\n",
    "Make sure your active cell is the empty one created earlier.\n",
    "Select \"Insert StringIO object\" from the drop-down menu.\n",
    "\n",
    "Note: This cell is marked as a hidden_cell because it contains\n",
    "sensitive credentials.\n",
    "\n",
    "#### Fix the code!\n",
    "\n",
    "We don't want to treat the replay as unicode text. We want the bytes.\n",
    "Change this import:\n",
    "```python\n",
    "from io import StringIO\n",
    "```\n",
    "To use StringIO like this:\n",
    "```python\n",
    "from StringIO import StringIO\n",
    "```\n",
    "\n",
    "Change this return line:\n",
    "```python\n",
    "return StringIO(resp2.text)\n",
    "```\n",
    "To use the \"content\" bytes like this:\n",
    "```python\n",
    "return StringIO(resp2.content)\n",
    "```\n",
    "\n",
    "#### Fix-up variable names\n",
    "The inserted code includes a generated method with credentials and then calls\n",
    "the generated method to set a variable with a name like \"data_1\". If you do\n",
    "additional inserts, the method can be re-used and the variable will change\n",
    "(e.g. \"data_2\").\n",
    "\n",
    "Later in the notebook, we set `replay_file = data_1`. So you might need to\n",
    "fix the variable name \"data_1\" to match your inserted code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a connection Cloudant\n",
    "\n",
    "#### Add a new connection to the project\n",
    "Use the DSX menu to select the project containing the notebook.\n",
    "\n",
    "Use \"Find and Add Data\" (look for the 10/01 icon)\n",
    "and its \"Connections\" tab. From there you can click \"Create Connection\".\n",
    "Give the connection a name and optionally a description.\n",
    "Under \"Service Category\" select the \"Data Service\" button.\n",
    "Use the \"Target service instance\" drop-down and select your Cloudant NoSQL DB instance\n",
    "(e.g., sc2-cloudantNoSQLDB-service).\n",
    "Make sure the connection you created is enabled with a checkbox in \"Connections\".\n",
    "\n",
    "\n",
    "#### Create an empty cell\n",
    "Use the \"+\" button above to create an empty cell to hold\n",
    "the inserted code and credentials.\n",
    "\n",
    "#### Add the Cloudant credentials to the notebook\n",
    "Use \"Find and Add Data\" (look for the 10/01 icon)\n",
    "and its \"Connections\" tab. You should see the\n",
    "connection name created earlier.\n",
    "Make sure your active cell is the empty one created earlier.\n",
    "Select \"Insert to code\" (below your connection name).\n",
    "\n",
    "Note: This cell is marked as a hidden_cell because it contains sensitive credentials.\n",
    "\n",
    "#### Fix-up variable names\n",
    "The inserted code includes a dictionary with credentials assigned to a variable\n",
    "with a name like \"credentials_1\". It may have a different name (e.g. \"credentials_2\").\n",
    "Rename it or reassign it if needed. The notebook code assumes it will be \"credentials_1\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the replay\n",
    "\n",
    "Load in the replay with sc2reader. We'll use bytes that the inserted code read from our\n",
    "DSX-ObjectStorage container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sc2reader\n",
    "from sc2reader.engine.plugins import APMTracker, ContextLoader, SelectionTracker\n",
    "from sc2reader.events import PlayerStatsEvent, UnitBornEvent, UnitDiedEvent, UnitDoneEvent, UnitTypeChangeEvent, UpgradeCompleteEvent\n",
    "\n",
    "# Some extra code here helps catch setup errors.\n",
    "try:\n",
    "    replay_file = data_1\n",
    "except NameError:\n",
    "    print('\\n'\n",
    "          'SETUP ERROR: Please follow the directions to add a .SC2Replay file and use\\n'\n",
    "          '             \"Insert to code\" to set the data_1 variable to the resulting bytes.\\n'\n",
    "          '             You may need to rename the data_* variable.')\n",
    "    raise\n",
    "\n",
    "replay = sc2reader.load_replay(\n",
    "    replay_file,\n",
    "    engine=sc2reader.engine.GameEngine(plugins=[ContextLoader(), APMTracker(), SelectionTracker()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poke poke poke\n",
    "\n",
    "With the replay added, we can now inspect the object in the notebook. We can easily get information like participants, winner, game length, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "replay.players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "replay.players[0].result, replay.players[1].result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "replay.map_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "replay.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Parsing events\n",
    "\n",
    "#### Establish some Unit and Building groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VESPENE_UNITS = [\"Assimilator\", \"Extractor\", \"Refinery\"]\n",
    "\n",
    "SUPPLY_UNITS = [\"Overlord\", \"Overseer\", \"Pylon\", \"SupplyDepot\"]\n",
    "\n",
    "WORKER_UNITS = [\"Drone\", \"Probe\", \"SCV\", \"MULE\"]\n",
    "\n",
    "BASE_UNITS = [\"CommandCenter\", \"Nexus\", \"Hatchery\", \"Lair\", \"Hive\", \"PlanetaryFortress\", \"OrbitalCommand\"]\n",
    "\n",
    "GROUND_UNITS = [\"Barracks\", \"Factory\", \"GhostAcademy\", \"Armory\", \"RoboticsBay\", \"RoboticsFacility\", \"TemplarArchive\",\n",
    "                \"DarkShrine\", \"WarpGate\", \"SpawningPool\", \"RoachWarren\", \"HydraliskDen\", \"BanelingNest\", \"UltraliskCavern\",\n",
    "                \"LurkerDen\", \"InfestationPit\"]\n",
    "\n",
    "AIR_UNITS = [\"Starport\", \"FusionCore\", \"RoboticsFacility\", \"Stargate\", \"FleetBeacon\", \"Spire\", \"GreaterSpire\"]\n",
    "\n",
    "TECH_UNITS = [\"EngineeringBay\", \"Armory\", \"GhostAcademy\", \"TechLab\", \"FusionCore\", \"Forge\", \"CyberneticsCore\",\n",
    "              \"TwilightCouncil\", \"RoboticsFacility\", \"RoboticsBay\", \"FleetBeacon\", \"TemplarArchive\", \"DarkShrine\",\n",
    "              \"SpawningPool\", \"RoachWarren\", \"HydraliskDen\", \"BanelingNest\", \"UltraliskCavern\", \"LurkerDen\", \"Spire\",\n",
    "              \"GreaterSpire\", \"EvolutionChamber\", \"InfestationPit\"]\n",
    "\n",
    "ARMY_UNITS = [\"Marine\", \"Colossus\", \"InfestorTerran\", \"Baneling\", \"Mothership\", \"MothershipCore\", \"Changeling\", \"SiegeTank\", \"Viking\", \"Reaper\",\n",
    "              \"Ghost\", \"Marauder\", \"Thor\", \"Hellion\", \"Hellbat\", \"Cyclone\", \"Liberator\", \"Medivac\", \"Banshee\", \"Raven\", \"Battlecruiser\", \"Nuke\", \"Zealot\",\n",
    "              \"Stalker\", \"HighTemplar\", \"Disruptor\", \"DarkTemplar\", \"Sentry\", \"Phoenix\", \"Carrier\", \"Oracle\", \"VoidRay\", \"Tempest\", \"WarpPrism\", \"Observer\",\n",
    "              \"Immortal\", \"Adept\", \"Zergling\", \"Overlord\", \"Hydralisk\", \"Mutalisk\", \"Ultralisk\", \"Roach\", \"Infestor\", \"Corruptor\",\n",
    "              \"BroodLord\", \"Queen\", \"Overseer\", \"Archon\", \"Broodling\", \"InfestedTerran\", \"Ravager\", \"Viper\", \"SwarmHost\"]\n",
    "\n",
    "ARMY_AIR = [\"Mothership\", \"MothershipCore\", \"Viking\", \"Liberator\", \"Medivac\", \"Banshee\", \"Raven\", \"Battlecruiser\",\n",
    "            \"Viper\", \"Mutalisk\", \"Phoenix\", \"Oracle\", \"Carrier\", \"VoidRay\", \"Tempest\", \"Observer\", \"WarpPrism\", \"BroodLord\",\n",
    "            \"Corruptor\", \"Observer\", \"Overseer\"]\n",
    "\n",
    "ARMY_GROUND = [k for k in ARMY_UNITS if k not in ARMY_AIR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then we establish our event parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_count(caller, event, key, add_value, start_val=0):\n",
    "    if len(caller.players[event.unit.owner.pid][key]) == 0:\n",
    "        caller.players[event.unit.owner.pid][key].append((0, 0))\n",
    "    # Get the last value\n",
    "    last_val = caller.players[event.unit.owner.pid][key][-1][1]\n",
    "    caller.players[event.unit.owner.pid][key].append((event.frame, last_val + add_value))\n",
    "\n",
    "\n",
    "def handle_expansion_events(caller, event):\n",
    "    if type(event) is UnitDoneEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in BASE_UNITS:\n",
    "            caller.players[event.unit.owner.pid][\"expansion_event\"].append((event.frame, \"+\", unit))\n",
    "            handle_count(caller, event, \"expansion_buildings\", 1, start_val=1)\n",
    "    elif type(event) is UnitDiedEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in BASE_UNITS:\n",
    "            caller.players[event.unit.owner.pid][\"expansion_event\"].append((event.frame, \"-\", unit))\n",
    "            handle_count(caller, event, \"expansion_buildings\", -1, start_val=1)\n",
    "    elif type(event) is UnitTypeChangeEvent:\n",
    "        if event.unit.name in BASE_UNITS:\n",
    "            caller.players[event.unit.owner.pid][\"expansion_event\"].append((event.frame, \"*\", event.unit.name))\n",
    "\n",
    "\n",
    "def handle_worker_events(caller, event):\n",
    "    if type(event) is PlayerStatsEvent:\n",
    "        caller.players[event.pid][\"workers_active\"].append((event.frame, event.workers_active_count))\n",
    "    elif type(event) is UnitBornEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in WORKER_UNITS:\n",
    "            caller.players[event.control_pid][\"worker_event\"].append((event.frame, \"+\", unit))\n",
    "    elif type(event) is UnitDiedEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in WORKER_UNITS:\n",
    "            caller.players[event.unit.owner.pid][\"worker_event\"].append((event.frame, \"-\", unit))\n",
    "\n",
    "\n",
    "def handle_supply_events(caller, event):\n",
    "    if type(event) is PlayerStatsEvent:\n",
    "        caller.players[event.pid][\"supply_available\"].append((event.frame, int(event.food_made)))\n",
    "        caller.players[event.pid][\"supply_consumed\"].append((event.frame, int(event.food_used)))\n",
    "        utilization = 0 if event.food_made == 0 else event.food_used / event.food_made\n",
    "        caller.players[event.pid][\"supply_utilization\"].append((event.frame, utilization))\n",
    "        worker_ratio = 0 if event.food_used == 0 else event.workers_active_count / event.food_used\n",
    "        caller.players[event.pid][\"worker_supply_ratio\"].append((event.frame, worker_ratio))\n",
    "    elif type(event) is UnitDoneEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in SUPPLY_UNITS:\n",
    "            caller.players[event.unit.owner.pid][\"supply_event\"].append((event.frame, \"+\", unit))\n",
    "    elif type(event) is UnitBornEvent:\n",
    "        # Specifically for Overlord\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit == \"Overlord\":\n",
    "            caller.players[event.control_pid][\"supply_event\"].append((event.frame, \"+\", unit))\n",
    "    elif type(event) is UnitDiedEvent:\n",
    "        # Buildings/ Overlord/Overseer\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in SUPPLY_UNITS:\n",
    "            caller.players[event.unit.owner.pid][\"supply_event\"].append((event.frame, \"-\", unit))\n",
    "    elif type(event) is UnitTypeChangeEvent:\n",
    "        if event.unit_type_name == \"Overseer\":\n",
    "            caller.players[event.unit.owner.pid][\"supply_event\"].append((event.frame, \"*\", event.unit_type_name))\n",
    "\n",
    "\n",
    "def handle_vespene_events(caller, event):\n",
    "    if type(event) is PlayerStatsEvent:\n",
    "        caller.players[event.pid][\"vespene_available\"].append((event.frame, event.vespene_current))\n",
    "        caller.players[event.pid][\"vespene_collection_rate\"].append((event.frame, event.vespene_collection_rate))\n",
    "        vesp_per_worker = 0 if event.workers_active_count == 0 else event.vespene_collection_rate / event.workers_active_count\n",
    "        caller.players[event.pid][\"vespene_per_worker_rate\"].append((event.frame, vesp_per_worker))\n",
    "        caller.players[event.pid][\"vespene_cost_active_forces\"].append((event.frame, event.vespene_used_active_forces))\n",
    "        caller.players[event.pid][\"vespene_spend\"].append((event.frame, event.vespene_used_current))\n",
    "        caller.players[event.pid][\"vespene_value_current_technology\"].append((event.frame, event.vespene_used_current_technology))\n",
    "        caller.players[event.pid][\"vespene_value_current_army\"].append((event.frame, event.vespene_used_current_army))\n",
    "        caller.players[event.pid][\"vespene_value_current_economic\"].append((event.frame, event.vespene_used_current_economy))\n",
    "        caller.players[event.pid][\"vespene_queued\"].append((event.frame, event.vespene_used_in_progress))\n",
    "        caller.players[event.pid][\"vespene_queued_technology\"].append((event.frame, event.vespene_used_in_progress_technology))\n",
    "        caller.players[event.pid][\"vespene_queued_army\"].append((event.frame, event.vespene_used_in_progress_technology))\n",
    "        caller.players[event.pid][\"vespene_queued_economic\"].append((event.frame, event.vespene_used_in_progress_economy))\n",
    "    elif type(event) is UnitDoneEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in VESPENE_UNITS:\n",
    "            caller.players[event.unit.owner.pid][\"vespene_event\"].append((event.frame, \"+\", unit))\n",
    "    elif type(event) is UnitDiedEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in VESPENE_UNITS:\n",
    "            caller.players[event.unit.owner.pid][\"vespene_event\"].append((event.frame, \"-\", unit))\n",
    "\n",
    "\n",
    "def handle_resources_events(caller, event):\n",
    "    if type(event) is PlayerStatsEvent:\n",
    "        caller.players[event.pid][\"mineral_destruction\"].append((event.frame, event.minerals_killed))\n",
    "        caller.players[event.pid][\"mineral_destruction_army\"].append((event.frame, event.minerals_killed_army))\n",
    "        caller.players[event.pid][\"mineral_destruction_economic\"].append((event.frame, event.minerals_killed_economy))\n",
    "        caller.players[event.pid][\"mineral_destruction_technology\"].append((event.frame, event.minerals_killed_technology))\n",
    "        caller.players[event.pid][\"mineral_loss\"].append((event.frame, event.minerals_lost))\n",
    "        caller.players[event.pid][\"mineral_loss_army\"].append((event.frame, event.minerals_lost_army))\n",
    "        caller.players[event.pid][\"mineral_loss_economic\"].append((event.frame, event.minerals_lost_economy))\n",
    "        caller.players[event.pid][\"mineral_loss_technology\"].append((event.frame, event.minerals_lost_technology))\n",
    "\n",
    "        caller.players[event.pid][\"vespene_destruction\"].append((event.frame, event.vespene_killed))\n",
    "        caller.players[event.pid][\"vespene_destruction_army\"].append((event.frame, event.vespene_killed_army))\n",
    "        caller.players[event.pid][\"vespene_destruction_economic\"].append((event.frame, event.vespene_killed_economy))\n",
    "        caller.players[event.pid][\"vespene_destruction_technology\"].append((event.frame, event.vespene_killed_technology))\n",
    "        caller.players[event.pid][\"vespene_loss\"].append((event.frame, event.vespene_lost))\n",
    "        caller.players[event.pid][\"vespene_loss_army\"].append((event.frame, event.vespene_lost_army))\n",
    "        caller.players[event.pid][\"vespene_loss_economic\"].append((event.frame, event.vespene_lost_economy))\n",
    "        caller.players[event.pid][\"vespene_loss_technology\"].append((event.frame, event.vespene_lost_technology))\n",
    "\n",
    "\n",
    "def handle_ground_events(caller, event):\n",
    "    if type(event) is UnitDoneEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in GROUND_UNITS:\n",
    "            count_name = \"_\".join([\"building\", unit, \"count\"])\n",
    "            caller.players[event.unit.owner.pid][\"ground_building\"].append((event.frame, \"+\", unit))\n",
    "            handle_count(caller, event, count_name, 1)\n",
    "    elif type(event) is UnitDiedEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in GROUND_UNITS:\n",
    "            count_name = \"_\".join([\"building\", unit, \"count\"])\n",
    "            caller.players[event.unit.owner.pid][\"ground_building\"].append((event.frame, \"-\", unit))\n",
    "            handle_count(caller, event, count_name, -1)\n",
    "    elif type(event) is UnitTypeChangeEvent:\n",
    "        if event.unit_type_name == \"LurkerDen\":\n",
    "            count_name = \"_\".join([\"building\", event.unit_type_name, \"count\"])\n",
    "            caller.players[event.unit.owner.pid][\"ground_building\"].append((event.frame, \"*\", event.unit_type_name))\n",
    "            handle_count(caller, event, count_name, 1)\n",
    "\n",
    "\n",
    "def handle_air_events(caller, event):\n",
    "    if type(event) is UnitDoneEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in AIR_UNITS:\n",
    "            count_name = \"_\".join([\"building\", unit, \"count\"])\n",
    "            caller.players[event.unit.owner.pid][\"air_building\"].append((event.frame, \"+\", unit))\n",
    "            handle_count(caller, event, count_name, 1)\n",
    "    elif type(event) is UnitDiedEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in AIR_UNITS:\n",
    "            count_name = \"_\".join([\"building\", unit, \"count\"])\n",
    "            caller.players[event.unit.owner.pid][\"air_building\"].append((event.frame, \"-\", unit))\n",
    "            handle_count(caller, event, count_name, -1)\n",
    "    elif type(event) is UnitTypeChangeEvent:\n",
    "        if event.unit_type_name == \"GreaterSpire\":\n",
    "            count_name = \"_\".join([\"building\", event.unit_type_name, \"count\"])\n",
    "            caller.players[event.unit.owner.pid][\"air_building\"].append((event.frame, \"*\", event.unit_type_name))\n",
    "            handle_count(caller, event, count_name, 1)\n",
    "\n",
    "\n",
    "def handle_unit_events(caller, event):\n",
    "    if type(event) is UnitBornEvent:\n",
    "        unit = event.unit_type_name\n",
    "        if unit in ARMY_UNITS:\n",
    "            unit_count_name = \"_\".join([\"unit\", unit, \"count\"])\n",
    "            caller.players[event.control_pid][\"army_event\"].append((event.frame, \"+\", unit))\n",
    "            handle_count(caller, event, unit_count_name, 1)\n",
    "            if unit in ARMY_AIR:\n",
    "                handle_count(caller, event, \"army_air\", 1)\n",
    "            elif unit in ARMY_GROUND:\n",
    "                handle_count(caller, event, \"army_ground\", 1)\n",
    "            handle_count(caller, event, \"army_count\", 1)\n",
    "    elif type(event) is UnitDoneEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in ARMY_UNITS:\n",
    "            unit_count_name = \"_\".join([\"unit\", unit, \"count\"])\n",
    "            caller.players[event.unit.owner.pid][\"army_event\"].append((event.frame, \"+\", unit))\n",
    "            handle_count(caller, event, unit_count_name, 1)\n",
    "            if unit in ARMY_AIR:\n",
    "                handle_count(caller, event, \"army_air\", 1)\n",
    "            elif unit in ARMY_GROUND:\n",
    "                handle_count(caller, event, \"army_air\", 1)\n",
    "            handle_count(caller, event, \"army_count\", 1)\n",
    "    elif type(event) is UnitDiedEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in ARMY_UNITS:\n",
    "            unit_count_name = \"_\".join([\"unit\", unit, \"count\"])\n",
    "            caller.players[event.unit.owner.pid][\"army_event\"].append((event.frame, \"-\", unit))\n",
    "            if unit in ARMY_AIR:\n",
    "                handle_count(caller, event, \"army_air\", -1)\n",
    "            elif unit in ARMY_GROUND:\n",
    "                handle_count(caller, event, \"army_ground\", -1)\n",
    "            handle_count(caller, event, unit_count_name, -1)\n",
    "            handle_count(caller, event, \"army_count\", -1)\n",
    "    elif type(event) is UnitTypeChangeEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if event.unit_type_name in ARMY_UNITS:\n",
    "            unit_count_name = \"_\".join([\"unit\", event.unit_type_name, \"count\"])\n",
    "\n",
    "            caller.players[event.unit.owner.pid][\"army_event\"].append((event.frame, \"*\", unit))\n",
    "\n",
    "            handle_count(caller, event, unit_count_name, 1)\n",
    "\n",
    "\n",
    "def handle_tech_events(caller, event):\n",
    "    if type(event) is UnitDoneEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in TECH_UNITS:\n",
    "            caller.players[event.unit.owner.pid][\"tech_building\"].append((event.frame, \"+\", unit))\n",
    "    elif type(event) is UnitDiedEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in TECH_UNITS:\n",
    "            caller.players[event.unit.owner.pid][\"tech_building\"].append((event.frame, \"-\", unit))\n",
    "    elif type(event) is UnitTypeChangeEvent:\n",
    "        if event.unit_type_name in [\"GreaterSpire\", \"LurkerDen\"]:\n",
    "            caller.players[event.unit.owner.pid][\"tech_building\"].append((event.frame, \"*\", event.unit_type_name))\n",
    "\n",
    "\n",
    "def handle_upgrade_events(caller, event):\n",
    "    if type(event) is UpgradeCompleteEvent and event.frame > 0:\n",
    "        if not event.upgrade_type_name.startswith(\"Spray\"):\n",
    "            caller.players[event.pid][\"upgrades\"].append((event.frame, event.upgrade_type_name))\n",
    "\n",
    "\n",
    "def handle_mineral_events(caller, event):\n",
    "    if type(event) is PlayerStatsEvent:\n",
    "        caller.players[event.pid][\"minerals_available\"].append((event.frame, event.minerals_current))\n",
    "        caller.players[event.pid][\"mineral_collection_rate\"].append((event.frame, event.minerals_collection_rate,))\n",
    "        caller.players[event.pid][\"mineral_cost_active_forces\"].append((event.frame, event.minerals_used_active_forces))\n",
    "        mins_per_worker = 0 if event.workers_active_count == 0 else event.minerals_collection_rate / event.workers_active_count\n",
    "        caller.players[event.pid][\"mineral_per_worker_rate\"].append((event.frame, mins_per_worker))\n",
    "        caller.players[event.pid][\"mineral_spend\"].append((event.frame, event.minerals_used_current))\n",
    "        caller.players[event.pid][\"mineral_value_current_technology\"].append((event.frame, event.minerals_used_current_technology))\n",
    "        caller.players[event.pid][\"mineral_value_current_army\"].append((event.frame, event.minerals_used_current_army))\n",
    "        caller.players[event.pid][\"mineral_value_current_economic\"].append((event.frame, event.minerals_used_current_economy))\n",
    "        caller.players[event.pid][\"mineral_queued\"].append((event.frame, event.minerals_used_in_progress))\n",
    "        caller.players[event.pid][\"mineral_queued_technology\"].append((event.frame, event.minerals_used_in_progress_technology))\n",
    "        caller.players[event.pid][\"mineral_queued_army\"].append((event.frame, event.minerals_used_in_progress_army))\n",
    "        caller.players[event.pid][\"mineral_queued_economic\"].append((event.frame, event.minerals_used_in_progress_economy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then we aggregate all of our event parsers for use by our ReplayData class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handlers = [handle_expansion_events, handle_worker_events, handle_supply_events, handle_mineral_events,\n",
    "            handle_vespene_events, handle_ground_events, handle_air_events, handle_tech_events, handle_upgrade_events,\n",
    "            handle_unit_events]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below we define our class ReplayData for helping us structure and process our replay files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ReplayData:\n",
    "    __parsers__ = handlers\n",
    "\n",
    "    @classmethod\n",
    "    def parse_replay(cls, replay=None, replay_file=None, file_object=None):\n",
    "        \n",
    "        replay_data = ReplayData(replay_file)\n",
    "        try:\n",
    "            # This is the engine that holds some required plugins for parsing\n",
    "            engine = sc2reader.engine.GameEngine(plugins=[ContextLoader(), APMTracker(), SelectionTracker()])\n",
    "               \n",
    "            if replay:\n",
    "                pass\n",
    "            elif replay_file and not file_object:\n",
    "                # Then we are not using ObjectStorage for accessing replay files\n",
    "                replay = sc2reader.load_replay(replay_file, engine=engine)\n",
    "            elif file_object:\n",
    "                # We are using ObjectStorage to access replay files\n",
    "                replay = sc2reader.load_replay(file_object, engine=engine)\n",
    "            else:\n",
    "                pass  # TODO: fix this logic\n",
    "            \n",
    "            # Get the number of frames (one frame is 1/16 of a second)\n",
    "            replay_data.frames = replay.frames\n",
    "            # Gets the game mode (if available)\n",
    "            replay_data.game_mode = replay.real_type\n",
    "            # Gets the map hash (if we want to download the map, or do map-based analysis)\n",
    "            replay_data.map_hash = replay.map_hash\n",
    "            \n",
    "            # Use the parsers to get data\n",
    "            for event in replay.events:\n",
    "                for parser in cls.__parsers__:\n",
    "                    parser(replay_data, event)\n",
    "            \n",
    "            # Check if there was a winner\n",
    "            if replay.winner is not None:\n",
    "                replay_data.winners = replay.winner.players\n",
    "                replay_data.losers = [p for p in replay.players if p not in replay.winner.players]\n",
    "            else:\n",
    "                replay_data.winners = []\n",
    "                replay_data.losers = []\n",
    "            # Check to see if expansion data is available\n",
    "            replay_data.expansion = replay.expasion\n",
    "            return replay_data\n",
    "        except:\n",
    "            # print our error and return NoneType object\n",
    "            print_exc()\n",
    "            return None\n",
    "        \n",
    "    def as_dict(self):\n",
    "        return {\n",
    "            \"processed_on\": datetime.utcnow().isoformat(),\n",
    "            \"replay_name\": self.replay,\n",
    "            \"expansion\": self.expansion,\n",
    "            \"frames\": self.frames,\n",
    "            \"mode\": self.game_mode,\n",
    "            \"map\": self.map_hash,\n",
    "            \"matchup\": \"v\".join(sorted([s.detail_data[\"race\"][0].upper() for s in self.winners + self.losers])),\n",
    "            \"winners\": [(s.pid, s.name, s.detail_data['race']) for s in self.winners],\n",
    "            \"losers\": [(s.pid, s.name, s.detail_data['race']) for s in self.losers],\n",
    "            \"stats_names\": [k for k in self.players[1].keys()],\n",
    "            \"stats\": {player: data for player, data in self.players.items()}\n",
    "                }\n",
    "\n",
    "    def __init__(self, replay):\n",
    "        self.players = defaultdict(lambda: defaultdict(list))\n",
    "        self.replay = replay\n",
    "        self.winners = []\n",
    "        self.losers = []\n",
    "        self.expansion = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Replay Files\n",
    "\n",
    "Parse our replay file to add event statistics. Use NumPy and pandas and more\n",
    "helper functions to prepare the data. Use Bokeh to create visualization in\n",
    "the notebook's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from traceback import print_exc\n",
    "\n",
    "from bokeh.charts import BoxPlot, Bar, Histogram\n",
    "from bokeh.io import output_notebook, reset_output\n",
    "from bokeh.models import Span, Range1d, Legend, BoxAnnotation, HoverTool, Arrow, NormalHead\n",
    "from bokeh.plotting import figure, show, gridplot, ColumnDataSource\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge(i, last_entry, sign=None, length=3):\n",
    "    if last_entry is not None:\n",
    "        if sign is not None:\n",
    "            # Check to see if this is a continuation\n",
    "            if last_entry[1] == i + length - 1 and last_entry[2] == sign:\n",
    "                return [(last_entry[0], i + length, sign)]\n",
    "            else:\n",
    "                return [last_entry, (i, i + length, sign)]\n",
    "        else:\n",
    "            # Check to see if this is a continuation\n",
    "            if last_entry[1] == i + length - 1:\n",
    "                return [(last_entry[0], i + length)]\n",
    "            else:\n",
    "                return [last_entry, (i, i + length)]\n",
    "    else:\n",
    "        if sign is not None:\n",
    "            return [(i, i + length, sign)]\n",
    "        else:\n",
    "            return [(i, i + length)]\n",
    "                \n",
    "\n",
    "                \n",
    "def detect_nelson_bias(src_data, x_bar):\n",
    "    # Bias is defined as 9 or more consecutive points sitting above or below our x-bar line\n",
    "    bias_ranges = []\n",
    "    length = 9\n",
    "    for i in range(len(src_data) - length):\n",
    "        last_entry = bias_ranges.pop() if len(bias_ranges) > 0 else None\n",
    "        if all([src_data[k] > x_bar for k in range(i, i + length)]):\n",
    "            sign = \"+\"\n",
    "            bias = merge(i, last_entry, sign=sign, length=length)\n",
    "            bias_ranges.extend(bias)\n",
    "        elif all([src_data[k] < x_bar for k in range(i, i+length)]):\n",
    "            sign = \"-\"\n",
    "            bias = merge(i, last_entry, sign=sign, length=length)\n",
    "            bias_ranges.extend(bias)\n",
    "        else:\n",
    "            if last_entry:\n",
    "                bias_ranges.append(last_entry)\n",
    "                \n",
    "    return bias_ranges\n",
    "\n",
    "def detect_nelson_trend(src_data, std):\n",
    "    # Trend is defined as 6 or more consecutive points all increasing or decreasing (or 6 or more consecutive non(increasing, decreasing) where difference between start and end points greater than 1.5 standard deviations )\n",
    "    trend_ranges = []\n",
    "    length = 6\n",
    "    for i in range(len(src_data) - length):\n",
    "        last_entry = trend_ranges.pop() if len(trend_ranges) > 0 else None\n",
    "        if (all(x<y for x, y in zip(src_data[i:i+length], src_data[i+1:i+length]))\n",
    "            or (all(x<=y for x,y in zip(src_data[i:i+length], src_data[i+1:i+length])) \n",
    "                and abs(src_data[i] - src_data[i+length]) >= 1.5*std)):\n",
    "            sign = \"+\"\n",
    "            trend_ranges.extend(merge(i, last_entry, sign=sign, length=length))\n",
    "        elif (all(x>y for x, y in zip(src_data[i:i+length], src_data[i+1:i+length])) \n",
    "            or (all(x>=y for x,y in zip(src_data[i:i+length], src_data[i+1:i+length]))\n",
    "                and abs(src_data[i] - src_data[i+length]) >= 1.5*std)):\n",
    "            sign = \"-\"\n",
    "            trend_ranges.extend(merge(i, last_entry, sign=sign, length=length))\n",
    "        else:\n",
    "            if last_entry:\n",
    "                trend_ranges.append(last_entry)\n",
    "    \n",
    "    return trend_ranges\n",
    "            \n",
    "def detect_nelson_oscillation(src_data):\n",
    "    # Oscillation is defined as 14 or more consecutive points, all alternating in direction\n",
    "    diff = lambda x, y: 1 if y - x > 0 else -1 if y - x  < 0 else None\n",
    "    oscillation_ranges = []\n",
    "    length=14\n",
    "    deltas = []\n",
    "    for i in range(len(src_data) - length):\n",
    "        last_entry = oscillation_ranges.pop() if len(oscillation_ranges) > 0 else None\n",
    "        sign = None\n",
    "        is_oscillating = True\n",
    "        for curr in range(i, i + length - 1):\n",
    "            if sign == None and curr == i:\n",
    "                sign = diff(src_data[curr], src_data[curr + 1])\n",
    "            elif sign is None and curr != i:\n",
    "                is_oscillating = False\n",
    "                break\n",
    "            else:\n",
    "                new_sign = diff(src_data[curr], src_data[curr + 1])\n",
    "                if new_sign is None or new_sign == sign:\n",
    "                    is_oscillating = False\n",
    "                    break\n",
    "                elif new_sign != sign and new_sign is not None:\n",
    "                    sign = new_sign\n",
    "        if is_oscillating:\n",
    "            # check if this is a continuation of a previous oscillation\n",
    "            oscillation_ranges.extend(merge(i, last_entry, length=length))\n",
    "            \n",
    "        else:\n",
    "            if last_entry:\n",
    "                oscillation_ranges.append(last_entry)\n",
    "    \n",
    "    return oscillation_ranges\n",
    "\n",
    "\n",
    "def avg_last_minute(process, pid, time, replay):\n",
    "    data = pd.DataFrame({\n",
    "            \"Data\": [k[1] for k in replay.stats[pid-1][process]]},\n",
    "            index=[int(k[0]/16) for k in replay.stats[pid - 1][process]])\n",
    "    \n",
    "    rolling = data.rolling(6).mean()\n",
    "    pct_change = data.pct_change()\n",
    "    ndx = data.index.get_loc(time, method=\"ffill\")\n",
    "\n",
    "    prev_ndx = max(ndx - 1, 0)\n",
    "    print(ndx, prev_ndx)\n",
    "    r_mean = rolling.get_value(rolling.index[ndx], \"Data\")\n",
    "    prev_mean = rolling.get_value(rolling.index[prev_ndx], \"Data\")\n",
    "    print(r_mean, prev_mean)\n",
    "    print(pct_change)\n",
    "    pcng = pct_change.get_value(rolling.index[ndx], \"Data\")\n",
    "\n",
    "    change = \"⬆️\" if r_mean > prev_mean else \"⬇️\" if r_mean < prev_mean else \"\"\n",
    "    \n",
    "    return r_mean if not pd.isnull(r_mean) else 0, change, pcng if not (pd.isnull(pcng) or pcng != np.Inf) else 0\n",
    "    \n",
    "\n",
    "# Define Nelson Rules Chart Generator\n",
    "def nelson_rules_chart_generator(src, timeseries, player, pid, process_name, unit_name, replay, plot_width=350,fill_color=\"blue\", line_color=\"blue\", line_width=2, annotations=None, fixed_lcl=None, fixed_ucl=None):\n",
    "    # We strip the first two data points (first data point is 0 and second data point should roughly be the same for all games)\n",
    "    x_bar = src[2:].mean()\n",
    "    std = src[2:].std()\n",
    "    ctrl_limits = [x_bar + (k*std) for k in range(-3, 4)]\n",
    "    ctrl_labels = [\"LCL\", \"-2σ\", \"-1σ\", \"x-bar\", \"1σ\", \"2σ\", \"UCL\"]\n",
    "    ctrl_colors = [\"#55597F\", \"#5D6DFF\",\"#A9B2FF\",\"#000000\", \"#FF9E9F\", \"#FF5253\",\"#7F2929\"]\n",
    "    ctrl_dash = [\"solid\", \"dashed\", \"dashed\", \"solid\", \"dashed\", \"dashed\", \"solid\"]\n",
    "    ctrl_legend = [\"{0} - {1:10.4f}\".format(cl[0], cl[1]) for cl in zip(ctrl_labels, ctrl_limits)]\n",
    "    ctrl_width = [3, 2, 2, 3, 2, 2, 3]\n",
    "    \n",
    "    \n",
    "    significant = lambda x: x > ctrl_limits[5] or x < ctrl_limits[1]\n",
    "    \n",
    "    hover = HoverTool(\n",
    "        tooltips=[\n",
    "            (\"time\", \"@x\"),\n",
    "            (\"value\", \"@y\")\n",
    "        ])\n",
    "    \n",
    "    p = figure(plot_width=plot_width, plot_height=300, x_axis_label=\"Game Time (in seconds)\", y_axis_label=unit_name, tools=[hover], toolbar_location=\"above\")\n",
    "    # Generate control lines\n",
    "    lines = []\n",
    "    source = ColumnDataSource(data=dict(x=[x/16 for x in timeseries], \n",
    "                                        y=src,\n",
    "                                        alpha=[1 if significant(y) and ndx > 2 else 0.7 for ndx, y in enumerate(src)], \n",
    "                                        radius=[6 if significant(y) and ndx > 2 else 4 for ndx, y in enumerate(src)], \n",
    "                                        ))\n",
    "    for ndx, cl in enumerate(ctrl_limits):\n",
    "        limit = cl\n",
    "            \n",
    "        lines.append(p.line([x/16 for x in timeseries], \n",
    "                            [limit]*len(timeseries), \n",
    "                            line_width=ctrl_width[ndx], \n",
    "                            line_dash=ctrl_dash[ndx], \n",
    "                            tags=[ctrl_labels[ndx] if k == 0 else None for k, _ in enumerate(timeseries)],  \n",
    "                            line_color=ctrl_colors[ndx]))\n",
    "        \n",
    "    \n",
    "    p.circle(\"x\", \"y\",\n",
    "             source=source,\n",
    "             alpha=\"alpha\", \n",
    "             radius=\"radius\", \n",
    "             fill_color=fill_color,  \n",
    "             line_width=line_width)\n",
    "    \n",
    "    \n",
    "    #Handle bias\n",
    "    bias_ranges = detect_nelson_bias(src, x_bar)\n",
    "    for rng in bias_ranges:\n",
    "        if rng[2] is \"+\":\n",
    "            p.add_layout(BoxAnnotation(bottom=x_bar, top=ctrl_limits[-1], left=timeseries[rng[0]]/16, right=timeseries[rng[1]]/16, fill_color=\"green\"))\n",
    "        elif rng[2] is \"-\":\n",
    "            p.add_layout(BoxAnnotation(top=x_bar, bottom=ctrl_limits[0], left=timeseries[rng[0]]/16, right=timeseries[rng[1]]/16, fill_color=\"red\"))\n",
    "            \n",
    "    # Handle trends\n",
    "    trend_ranges = detect_nelson_trend(src, std)\n",
    "    for rng in trend_ranges:\n",
    "        if rng[2] is \"+\":\n",
    "            p.add_layout(Arrow(end=NormalHead(line_color=\"goldenrod\",\n",
    "                                              fill_color=\"goldenrod\"),\n",
    "                               x_start=timeseries[rng[0]]/16,\n",
    "                               y_start=src[rng[0]],\n",
    "                               x_end=timeseries[rng[1]]/16,\n",
    "                               y_end=src[rng[1]],\n",
    "                               line_width=4,\n",
    "                               line_alpha=0.6,\n",
    "                               line_dash=\"solid\"))\n",
    "        elif rng[2] is \"-\":\n",
    "            p.add_layout(Arrow(end=NormalHead(line_color=\"#7F0000\",\n",
    "                                              fill_color=\"#7F0000\"),\n",
    "                               x_start=timeseries[rng[0]]/16,\n",
    "                               y_start=src[rng[0]],\n",
    "                               x_end=timeseries[rng[1]]/16,\n",
    "                               y_end=src[rng[1]],\n",
    "                               line_width=4,\n",
    "                               line_alpha=0.6,\n",
    "                               line_dash=\"solid\"))\n",
    "    \n",
    "    p.title.text = \"Nelson Rules Process Chart - {0} for {1}: x-bar={2}, σ={3}\".format(process, player, x_bar, std)\n",
    "    p.y_range = p.y_range = Range1d(ctrl_limits[0] - 0.125 * ctrl_limits[0],  1.125 * ctrl_limits[-1])\n",
    "    \n",
    "    \n",
    "    # TODO: legend = Legend(items=list(zip(ctrl_legend, [[l] for l in lines])), location=(10,-30))\n",
    "    legend = Legend(tags=list(zip(ctrl_legend, [[l] for l in lines])), location=(10,-30))\n",
    "    p.add_layout(legend, \"right\")\n",
    "    \n",
    "    return p, ctrl_limits, min(src[2:]), max(src[2:]), timeseries[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "replay_object = ReplayData.parse_replay(replay=replay)\n",
    "replay_dict = replay_object.as_dict()\n",
    "\n",
    "players = {}\n",
    "for player in replay_dict[\"winners\"]:\n",
    "    players[int(player[0])] = {\"full\": \"Winning Player {num}: {name} ({race})\".format(num=player[0], name=player[1], race=player[2]),\n",
    "                               \"short\": \"{name} ({race})\".format(name=player[1], race=player[2]) }\n",
    "for player in replay_dict[\"losers\"]:\n",
    "    players[int(player[0])] = {\"full\": \"Losing Player {num}: {name} ({race})\".format(num=player[0], name=player[1], race=player[2]),\n",
    "                               \"short\": \"{name} ({race})\".format(name=player[1], race=player[2]) }\n",
    "\n",
    "econ = [\"mineral_collection_rate\", \"vespene_collection_rate\", \"workers_active\", \"supply_utilization\", \"worker_supply_ratio\"]\n",
    "units = [\"Minerals per Minute (MPM)\", \"Vespene per Minute (VPM)\", \"Workers\", \"Supply Used / Supply Available\", \"Workers / Supply Used\"]\n",
    "\n",
    "player_charts = defaultdict(dict)\n",
    "player_aggregate = defaultdict(dict)\n",
    "for pid, player in players.items():\n",
    "    for ndx, process in enumerate(econ):\n",
    "        # Generate charts per player\n",
    "        # TODO: use pid or str(pid) in next 2 lines?\n",
    "        timeseries = [k[0] for k in replay_dict[\"stats\"][pid][process]]\n",
    "        proc_data = [j[1] for j in replay_dict[\"stats\"][pid][process]]\n",
    "        \n",
    "        player_charts[pid][process], limits, v_min, v_max, game_length = nelson_rules_chart_generator(pd.Series(proc_data),\n",
    "                                                                                                timeseries,\n",
    "                                                                                                player[\"full\"],\n",
    "                                                                                                pid,\n",
    "                                                                                                process,\n",
    "                                                                                                units[ndx],\n",
    "                                                                                                replay,\n",
    "                                                                                                fixed_lcl=0)\n",
    "    \n",
    "        player_aggregate[process][pid] = proc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "grid = [[player_charts[k][measurement] for k in player_charts] for ndx, measurement in enumerate(econ)]\n",
    "\n",
    "\n",
    "real_grid = []\n",
    "\n",
    "for ndx in range(len(grid)):\n",
    "    sample_max = min([len(player_aggregate[econ[ndx]][j]) for j in player_aggregate[econ[ndx]].keys()])\n",
    "    # Remember, we are removing the first 20 samples (beginning of game should be the same for all, so data is useless)\n",
    "    frame = pd.DataFrame({ \"Data\": [player_aggregate[econ[ndx]][1][k] for k in range(2,sample_max)] + [player_aggregate[econ[ndx]][2][l] for l in range(2,sample_max)],\n",
    "                           \"Player\": [players[(i//sample_max) + 1][\"short\"] for i in range(0,len(players.keys())*(sample_max - 2))]})\n",
    "    \n",
    "    median_1 = np.median(player_aggregate[econ[ndx]][1][2:])\n",
    "    median_2 = np.median(player_aggregate[econ[ndx]][2][2:])\n",
    "    \n",
    "    print(econ[ndx], median_1, median_2)\n",
    "    \n",
    "    bp = BoxPlot(frame, values=\"Data\", \n",
    "                 label=\"Player\", \n",
    "                 title=\"{0} grouped by Player\".format(units[ndx]), \n",
    "                 color=\"Player\", \n",
    "                 marker=\"square\", \n",
    "                 whisker_color=\"Player\", \n",
    "                 plot_height=200)\n",
    "    real_grid.append([bp]),\n",
    "    real_grid.append(grid[ndx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show(gridplot(real_grid, sizing_mode=\"scale_width\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Replay Files\n",
    "\n",
    "Now that we have loaded and processed the replay, we can store\n",
    "it for future use and aggregation.\n",
    "\n",
    "The replay_object has an as_dict() method to give us JSON.\n",
    "\n",
    "We'll store this in Cloudant for future use.\n",
    "\n",
    "1) Connect to Cloudant with our Bluemix credentials.\n",
    "\n",
    "2) Create 'sc2replays' and 'sc2recents' databases.\n",
    "\n",
    "3) Store the current replay as a document in the 'sc2replays' database.\n",
    "\n",
    "4) Store the current replay as a document in the 'sc2recents' database and remove the older replays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Peek at what is in the object?\n",
    "\n",
    "# from pprint import pprint\n",
    "# pprint(replay_object.as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cloudant import cloudant\n",
    "\n",
    "# Some extra code here helps catch setup errors.\n",
    "try:\n",
    "    sc2replay_creds = credentials_1\n",
    "except NameError:\n",
    "    print('\\n'\n",
    "          'SETUP ERROR: Please follow the directions to add Cloudant credentials to the notebook.\\n'\n",
    "          '             You may need to rename the credentials_* variable.')\n",
    "    raise\n",
    "\n",
    "# Now we need to send this data to 2 databases \"sc2replays for aggregating, and sc2recents.\n",
    "\n",
    "# With a cloudant.com account use the account and user.\n",
    "# Example for cloudant.com account:\n",
    "#     with cloudant(sc2replay_creds[\"user\"], sc2replay_creds[\"password\"], account=\"e-sports\") as esports:\n",
    "\n",
    "# Connect to cloudant service with Bluemix credentials url and username.\n",
    "with cloudant(sc2replay_creds[\"username\"], sc2replay_creds[\"password\"], url=sc2replay_creds['url']) as esports:\n",
    "    session = esports.session()\n",
    "    if 'sc2replays' not in esports.all_dbs():\n",
    "        esports.create_database('sc2replays')\n",
    "    print(esports)\n",
    "    sc2replays = esports['sc2replays']\n",
    "    document = sc2replays.create_document(replay_object.as_dict())\n",
    "    if document.exists():\n",
    "        print(\"new sc2replays entry saved. Latest id: {0}\".format(document[\"_id\"]))\n",
    "        \n",
    "    if 'sc2recents' not in esports.all_dbs():\n",
    "        esports.create_database('sc2recents')\n",
    "    sc2recents = esports['sc2recents']\n",
    "    # clear out everything in sc2recents db\n",
    "    for d in sc2recents:\n",
    "        print(\"removing\", d[\"_id\"])\n",
    "        d.delete()\n",
    "        \n",
    "    document = sc2recents.create_document(replay_object.as_dict())\n",
    "    if document.exists():\n",
    "        print(\"new sc2recents entry saved. Latest id: {0}\".format(document[\"_id\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 1.6",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}